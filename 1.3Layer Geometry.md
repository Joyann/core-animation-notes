## 1.Layout

UIView有三个主要的layout属性：frame,bounds,center。CALayer有三个等价的：frame,bounds,position。

__frame__描述的是layer的外部坐标；__bounds__描述的是layer的内部坐标；__center__和__posotion__都代表相对于父图层anchorPoint的位置，anchorPoint后面会介绍到，现在就当成是图层的中点。这三个属性如图：
![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/11.jpeg)

---

视图的frame,bounds和center属性实际上仅仅是存取方法，这些属性改变的实际是其下层CALayer的响应属性。当你改变view的frame属性，你实际上改变的是其下层CALayer的属性。你不能够独立于它的layer之外改变view的frame。

frame属性对于view和layer来说并非是清晰的属性；它是一个虚拟属性，是根据bounds,position和transform计算来的，所以这些属性任意改变一个，frame都会被改变。相反的，改变frame的值同样会影响到他们当中的值。

你在使用transform的时候需要注意，因为当一个layer旋转或者缩放的时候，frame实际上代表了覆盖在图层旋转之后的整个轴对齐的矩形区域，也就是说frame的宽高可能和bounds的宽高不再一致了。如图：

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/12.jpeg)

---

## 2.anchorPoint

之前提到过，view的center属性和layer的position属性都指定了相对于父图层的anchorPoint的位置。你可以认为anchorPoint是用来移动图层的handle。

默认的，anchorPoint是图层的中心点。

anchorPoint属性并没有被UIView接口暴露，这也是为什么UIView的属性叫做"center"而不叫"position"，因为在UIView中的anchorPoint默认是中点，不可修改，所以叫做"center"；而在CALayer中的anchorPoint是可以修改的，所以叫做"position"。如图改变layer的anchorPoint:

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/13.jpeg)

注意：改变了anchorPoint，position属性保持固定的值并没有发生改变，但是frame却移动了。

如图可以看到，在变化之前，anchorPoint是图层中点，此时就是我们UIView的"center"属性；
在变化之后，anchorPoint不再是图层中点，此时就是我们CALayer的"position"属性；

当改变position的时候，左图会使layer围绕中点移动；而右图会使layer围绕左上角的点移动。也就是说，此时是相同的position({30,35})，一个是围绕中点移动，一个是围绕左上角点移动，frame属性被改变了。

再说的明白点就是：

UIView的center属性，默认anchorPoint在图层中心，即无论怎么移动（改变center属性）都会使view围绕中心移动；

CALayer的position属性，默认anchorPoint在图层中心，即移动的时候（改变position属性）会使layer围绕中心移动；但是相对于view，此时anchorPoint是可以改变的，假如我把anchorPoint改变成左上角的点，那么此时移动（改变position属性），则图层围绕的是左上角的点移动。position和center决定图层的位置，而anchorPoint则决定是围绕哪个点移动。(改变anchorPoint的值改变了frame的值，事实上位置没有变，只不过围绕的点不同，造成了frame的不同)

---

和第二章提到的contentsRect和contentsCenter属性类似，anchorPoint用单位坐标来描述，也就是图层的相对坐标，图层左上角是{0, 0}，右下角是{1, 1}，因此默认坐标是{0.5, 0.5}。anchorPoint可以通过指定x和y值小于0或者大于1，使它放置在图层范围之外。

那么在什么时候需要改变anchorPoint的值呢？默认的center已经很清楚可以改变图层位置，为什么还修改anchorPoint造成不必要的困惑呢？我们来创建一个模拟闹钟的项目就可以清楚了。

钟面和钟表由四张图片组成（图3.4），为了简单说明，我们还是用传统的方式来装载和加载图片，使用四个UIImageView实例（当然你也可以用正常的视图，设置他们图层的contents图片）。

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/14.jpeg)

闹钟的组件通过IB来排列，这些图片视图嵌套在一个容器视图之内，并且自动调整和自动布局都被禁用了。这是因为自动调整会影响到视图的frame，当视图旋转的时候，frame是会发生改变的，这将会导致一些布局上的失灵。

我们用NSTimer来更新闹钟，使用视图的transform属性来旋转钟表（如果你对这个属性不太熟悉，不要着急，我们将会在第5章“变换”当中详细说明）。

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/15.jpg)

---

代码如下：

    @interface ViewController ()
    @property (nonatomic, weak) IBOutlet UIImageView *hourHand;
    @property (nonatomic, weak) IBOutlet UIImageView *minuteHand;
    @property (nonatomic, weak) IBOutlet UIImageView *secondHand;
    @property (nonatomic, weak) NSTimer *timer;
    @end
    @implementation ViewController
    - (void)viewDidLoad
    {
        [super viewDidLoad];
        //start timer
        self.timer = [NSTimer scheduledTimerWithTimeInterval:1.0 target:self selector:@selector(tick) userInfo:nil repeats:YES];
        //set initial hand positions
        [self tick];
    }
    - (void)tick
    {
        //convert time to hours, minutes and seconds
        NSCalendar *calendar = [[NSCalendar alloc] initWithCalendarIdentifier:NSGregorianCalendar];
        NSUInteger units = NSHourCalendarUnit | NSMinuteCalendarUnit | NSSecondCalendarUnit;
        NSDateComponents *components = [calendar components:units fromDate:[NSDate date]];
        CGFloat hoursAngle = (components.hour / 12.0) * M_PI * 2.0;
        //calculate hour hand angle //calculate minute hand angle
        CGFloat minsAngle = (components.minute / 60.0) * M_PI * 2.0;
        //calculate second hand angle
        CGFloat secsAngle = (components.second / 60.0) * M_PI * 2.0;
        //rotate hands
        self.hourHand.transform = CGAffineTransformMakeRotation(hoursAngle);
        self.minuteHand.transform = CGAffineTransformMakeRotation(minsAngle);
        self.secondHand.transform = CGAffineTransformMakeRotation(secsAngle);
    }
    @end
    
运行项目，看起来有点奇怪，因为钟表的图片在围绕着中心旋转，这并不是我们期待的一个支点。

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/16.jpeg)

你也许会认为可以在Interface Builder当中调整指针图片的位置来解决，但其实并不能达到目的，因为如果不放在钟面中间的话，同样不能正确的旋转。

也许在图片末尾添加一个透明空间也是个解决方案，但这样会让图片变大，也会消耗更多的内存，这样并不优雅。

更好的方案是使用anchorPoint属性，我们来在-viewDidLoad方法中添加几行代码来给每个钟指针的anchorPoint做一些平移：

    - (void)viewDidLoad 
    {
        [super viewDidLoad];
        // adjust anchor points
        self.secondHand.layer.anchorPoint = CGPointMake(0.5f, 0.9f); 
        self.minuteHand.layer.anchorPoint = CGPointMake(0.5f, 0.9f); 
        self.hourHand.layer.anchorPoint = CGPointMake(0.5f, 0.9f);
        // start timer
    }
    
现在则一切正常了：

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/17.jpeg)



## 3.Coordinate Systems

我们已经知道，图层的position依赖于其父图层的bounds，如果父图层移动，那么所有子图层都会跟着移动。

这样有的时候很方便，但有的时候你想知道一个图层的__绝对位置__，或者相当于其他图层的位置，而不是当前父图层的位置。

CALayer给不同坐标系间的图层转换提供了一些方法：

    - (CGPoint)convertPoint:(CGPoint)point fromLayer:(CALayer *)layer; 
    - (CGPoint)convertPoint:(CGPoint)point toLayer:(CALayer *)layer; 
    - (CGRect)convertRect:(CGRect)rect fromLayer:(CALayer *)layer;
    - (CGRect)convertRect:(CGRect)rect toLayer:(CALayer *)layer;
    
这些方法可以让你把一个坐标系中定义的点或者矩形转换成另一个坐标系相应的点或者矩形。

## 4.Flipped Geometry

> 常规说来，在iOS上，一个图层的position位于父图层的左上角，但是在Mac OS上，通常是位于左下角。Core Animation可以通过geometryFlipped属性来适配这两种情况，它决定了一个图层的坐标是否相对于父图层垂直翻转，是一个BOOL类型。在iOS上通过设置它为YES意味着它的子图层将会被垂直翻转，也就是将会沿着底部排版而不是通常的顶部（它的所有子图层也同理，除非把它们的geometryFlipped属性也设为YES）。

## 4.The Z Axis

UIView是严格的二维坐标，而CALayer存在于一个三维坐标中。除了我们讨论过的position和anchorPoint属性，CALayer还有两个属性：__zPosition__和__anchorPointZ__，这两个属性都是描述图层在Z轴方向上的坐标，且都是__浮点类型__。

zPosition属性并不常用，我们以后会说到CATranform3D，你会知道如何在三维空间移动和旋转图层，除了变换以外，zPosition还可以改变图层的显示顺序。

我们知道如果原来有一图层，我们新增图层上去会覆盖原有图层。但是如果改变原有图层的zPosition就可以让原有图层离我们更近。例子如下：

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/18.jpg)

如图，红色图层盖住了绿色图层。

我们现在希望，改变显示顺序，让绿色图层离我们更近一些。这时候我们就可以改变绿色图层的zPosition。代码如下：

    @interface ViewController ()
    @property (nonatomic, weak) IBOutlet UIView *greenView;
    @property (nonatomic, weak) IBOutlet UIView *redView;
    @end
    @implementation ViewController
    - (void)viewDidLoad
    {
        [super viewDidLoad];
        
        //move the green view zPosition nearer to the camera
        self.greenView.layer.zPosition = 1.0f;
    }
    @end

注意，我们并不需要将zPosition设置的太高，因为视图都非常的薄，所以给绿色图层的zPosition一个point就可以使其高于红色图层，当然0.1,0.0001也可以做到，但是最好不要这样，因为浮点类型四舍五入可能会造成麻烦。

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/19.jpeg)

## 5.Hit Testing

第一章，"The Layer Tree", 说明了最好使用views和backing layers而不是创建独立的图层关系，其中的一个原因就是当用图层的时候，要处理额外的复杂的触摸事件。

CALayer并不关心响应链，因此它不能直接处理触摸事件或者手势，但是它提供了方法可以让你自己来实现处理触摸事件：__ -containsPoint:和 -hitTest:__。

-containsPoint:方法接受一个在本图层坐标下的CGPoint，如果这个point在图层内，则返回YES；若不在，返回NO。例子如下：

    @interface ViewController ()
    @property (nonatomic, weak) IBOutlet UIView *layerView;
    @property (nonatomic, weak) CALayer *blueLayer;
    @end
    @implementation ViewController
    - (void)viewDidLoad
    {
        [super viewDidLoad];
        //create sublayer
        self.blueLayer = [CALayer layer];
        self.blueLayer.frame = CGRectMake(50.0f, 50.0f, 100.0f, 100.0f);
        self.blueLayer.backgroundColor = [UIColor blueColor].CGColor;
        //add it to our view
        [self.layerView.layer addSublayer:self.blueLayer];
    }
    - (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event
    {
        //get touch position relative to main view
        CGPoint point = [[touches anyObject] locationInView:self.view];
        //convert point to the white layer's coordinates
        point = [self.layerView.layer convertPoint:point fromLayer:self.view.layer];
        //get layer using containsPoint:
        if ([self.layerView.layer containsPoint:point]) {
            //convert point to blueLayer’s coordinates
            point = [self.blueLayer convertPoint:point fromLayer:self.layerView.layer];
            if ([self.blueLayer containsPoint:point]) {
                [[[UIAlertView alloc] initWithTitle:@"Inside Blue Layer" 
                                            message:nil
                                           delegate:nil 
                                  cancelButtonTitle:@"OK"
                                  otherButtonTitles:nil] show];
            } else {
                [[[UIAlertView alloc] initWithTitle:@"Inside White Layer"
                                            message:nil 
                                           delegate:nil
                                  cancelButtonTitle:@"OK"
                                  otherButtonTitles:nil] show];
            }
        }
    }
    @end

![](/Users/joyann/Desktop/Developer/Objective-C/CoreAnimation-Code/Image/20.jpeg)

可以看到，这需要我们把触摸坐标转换成每个图层坐标系下的坐标，很不方便。

---

-hitTest:方法同样也接受一个CGPoint参数，但是返回类型不再是BOOL，而是返回图层本身，或者包含这个坐标点的叶子节点的图层。这意味着不再需要像使用-containsPoint:那样，人工地在每个子图层变换或者测试点击的坐标。如果这个点在最外面图层的范围之外，则返回nil。例子如下：

    - (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event
    {
        //get touch position
        CGPoint point = [[touches anyObject] locationInView:self.view];
        //get touched layer
        CALayer *layer = [self.layerView.layer hitTest:point];
        //get layer using hitTest
        if (layer == self.blueLayer) {
            [[[UIAlertView alloc] initWithTitle:@"Inside Blue Layer"
                                        message:nil
                                       delegate:nil
                              cancelButtonTitle:@"OK"
                              otherButtonTitles:nil] show];
        } else if (layer == self.layerView.layer) {
            [[[UIAlertView alloc] initWithTitle:@"Inside White Layer"
                                        message:nil
                                       delegate:nil
                              cancelButtonTitle:@"OK"
                              otherButtonTitles:nil] show];
        }
    }

注意：当使用-hitTest:方法时，检测的顺序是图层树中的图层顺序，也就是说，即使你改变了下层图层的zPosition，使其在屏幕上显示离我们更近，但是事件传递的顺序并没有改变。

这意味着如果改变了图层的z轴顺序，你会发现不能检测离我们最近的点击事件，这时因为它被另一个图层挡住了，虽然挡住我们的图层zPosition的值更小，但是在图层树中的顺序靠前。我们将在以后详细讨论这个问题。

## 6.Automatic Layout

> 你可能用过UIViewAutoresizingMask类型的一些常量，应用于当父视图改变尺寸的时候，相应UIView的frame也跟着更新的场景（通常用于横竖屏切换）。

> 在iOS6中，苹果介绍了自动排版机制，它和自动调整不同，并且更加复杂。

> 在Mac OS平台，CALayer有一个叫做layoutManager的属性可以通过CALayoutManager协议和CAConstraintLayoutManager类来实现自动排版的机制。但由于某些原因，这在iOS上并不适用。

> 当使用视图的时候，可以充分利用UIView类接口暴露出来的UIViewAutoresizingMask和NSLayoutConstraintAPI，但如果想随意控制CALayer的布局，就需要手工操作。最简单的方法就是使用CALayerDelegate如下函数：

    - (void)layoutSublayersOfLayer:(CALayer *)layer;
> 当图层的bounds发生改变，或者图层的-setNeedsLayout方法被调用的时候，这个函数将会被执行。这使得你可以手动地重新摆放或者重新调整子图层的大小，但是不能像UIView的autoresizingMask和constraints属性做到自适应屏幕旋转。

> 这也是为什么最好使用视图而不是单独的图层来构建应用程序的另一个重要原因之一。

